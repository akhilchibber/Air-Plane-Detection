{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true},"cell_type":"markdown","source":"@rhammell has kindly provided a set of satellite images of ships as well as a set of satellite images of planes.\nWe ask the logical question - can we distinguish planes from ships? Of course it depends whether we can pool all the training data together ...\n \n i.e. if any of the \"not-ship\" images happen to contain planes but are marked as \"0\"\n and if any of the \"not-plane\" images happen to contain ships but are marked as \"0\"\n We'll try and see how it goes.\n\n We'll have to downsample the ship-images as they are 80px a side instead of 20px a side - so we'll use skimage.transform's \"resize\" for downsampling with built-in anti-aliasing. "},{"metadata":{"trusted":true,"_uuid":"d789d25bd3d3b8f4f05b6f5a5bb2f8f00c273b56"},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# We'll build the CNN as a sequence of layers.\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n\n# Libraries to handle the data\nimport json\nfrom PIL import Image # PIL = Python Image Library\nfrom skimage.transform import resize","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb916645b84ee765e6c34b9072b2275fe132dca0"},"cell_type":"markdown","source":"Grab planes data, then append the ships data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"file = open('../input/planesnet/planesnet.json')\ndataset = json.load(file)\nfile.close()\n\n# Plane Images are 20x20 pixels \npixel_width = 20\npixel_height = 20\nnumChannels = 3 # its 3D because it's RGB image data\ninput_shape = (pixel_width, pixel_height,numChannels) \n\nimages = []\nfor index in range( len( dataset['data'] )):\n    pixel_vals = dataset['data'][index]\n    arr = np.array(pixel_vals).astype('uint8')\n    arr = arr / 255.0 # Need to scale this here as shipimages will be fractional after downsampling\n    im = arr.reshape(( numChannels, pixel_width * pixel_height)).T.reshape( input_shape )\n    images.append( im )\n           \nfile = open('../input/ships-in-satellite-imagery/shipsnet.json')\nshipdataset = json.load(file)\nfile.close()\n    \n# Ship Images are 80x80 pixels \nshippixel_width = 80\nshippixel_height = 80\nshipnumChannels = 3 # its 3D because it's RGB image data\nshipinput_shape = (shippixel_width, shippixel_height,shipnumChannels) \n\nfor index in range( len( shipdataset['data'] )):\n    pixel_vals = shipdataset['data'][index]\n    arr = np.array(pixel_vals).astype('uint8')\n    im = arr.reshape((3, shippixel_width * shippixel_height)).T.reshape( shipinput_shape )\n    image_resized = resize(im, (pixel_width, pixel_height),mode='constant')\n    # this returns the image_resized in RGB format as (float,float,float)\n    images.append( image_resized )\n    \nimages = np.array( images )\nlabels = np.array(dataset['labels'])\n\nshiplabels = 2* np.array(shipdataset['labels'])\nlabels = np.hstack( (labels, shiplabels))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"190ba887c6cb98b6a50a25f38620a4d8035d9a5b"},"cell_type":"markdown","source":"Split data into test and training sets, then build the model."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"93d3af3af339abc242bcc92613989f8708dbdec6"},"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.20)\n\nbatch_size = 32 \nepochs = 10 #number of times to pass over the training data to fit\n\n# After making a first pass at the CNN, we'll come back and set this Flag\n# to True to improve our accuracy by adding extra layers \nADD_EXTRA_LAYERS = True\n\n# Initialize the CNN as a sequence of layers\nmodel = Sequential()\n\n# For the first Convolutional Layer we'll choose 32 filters (\"feature detectors\"), \n# each with kernel size=(3,3), use activation=ReLU to add nonlinearity\nmodel.add(Conv2D(32, (3,3), activation='relu', input_shape=input_shape))\n\n# Downsample by taking Max over (2,2) non-overlapping blocks => helps with spatial/distortion invariance\n# with the added benefit of reducing compute time :-)\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n# Later we can add extra convolutional layers to improve our accuracy\nif( ADD_EXTRA_LAYERS ):\n    model.add(Conv2D(32, (3,3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.2)) # Add Dropout layer to reduce overfitting\n    \n    model.add(Conv2D(64, (3,3), activation='relu'))\n    #model.add(MaxPooling2D(pool_size=(2,2), dim_ordering=\"tf\"))\n    model.add(Dropout(0.5)) # Add Dropout layer to reduce overfitting\n    \n# Flatten all the pooled feature maps into a single vector\nmodel.add(Flatten())\n\n# Append an ANN on the end of the CNN\n# Choose 256 and then 128 nodes on the hidden layers - typically we choose a number that is \n# - not too small so the model can perform well, \n# - and not too large as otherwise the compute time is too long\nif( ADD_EXTRA_LAYERS ):\n    model.add(Dense(units=256, activation='relu'))\n    model.add(Dropout(0.2))\n    \nmodel.add(Dense(units=128, activation='relu'))\n\nnumberOfCategories = 3\nmodel.add(Dense(units=numberOfCategories, activation='softmax'))\n\n# Compile model - \n# Choose the 'Adam' optimizer for Stochastic Gradient Descent\n# https://arxiv.org/pdf/1609.04747.pdf\n# We have a categorical outcome so we use 'categorical_cross_entropy'\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n\n# We need to expand the labels to look like multiple-output nodes! \n# So if the category was 3, then the 3rd node would have a 1 in it!\ny_train = keras.utils.to_categorical( y_train, numberOfCategories)\ny_test = keras.utils.to_categorical( y_test, numberOfCategories )\n\n# We use Image Augmentation as the number of images is small.\n# (We generate extra training images by applying various distortions to the samples\n# in our training set. This increases the size of our training set and so helps reduce\n# overfitting.) \nfrom keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    # These first four parameters if true would result in scaling of the input images,  \n    # which in this situation reduce the ability of the CNN to train properly.\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    rotation_range=10,\n    horizontal_flip=True,\n    vertical_flip=True)\n\ntraining_set = train_datagen.flow(x_train, y_train, batch_size=batch_size)\n\ntest_datagen = ImageDataGenerator()\ntest_set = test_datagen.flow(x_test, y_test, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"e31e81a38d1e2742bf12bbab8f233ae40ec35310"},"cell_type":"code","source":"# fits the model on batches with real-time data augmentation:\nmodel.fit_generator( training_set,\n                    steps_per_epoch=len(x_train) / batch_size, \n                    validation_data=test_set,\n                    validation_steps=len(x_test)/batch_size,\n                    epochs=epochs)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"e98745d0a8ca3bf4bec5ac4b6ebc4e5fde8327aa"},"cell_type":"markdown","source":"With ADD_EXTRA_LAYERS = False we have an accuracy of ~95%. \nWhen we set this flag to true to add in the extra layers, our accuracy does not change too much ...so it looks like we'll have to do K-Fold Cross Validation to check that we're really getting improved performance with the extra layers.\n"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"63653d64f27f1e3d10552928d103eebcef43dfd2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}